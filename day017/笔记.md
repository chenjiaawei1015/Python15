# re模块

## 查找

### findall

- 一次性返回所有结果

  ```python
  import re
  
  s = "123abc45de67"
  
  res_list = re.findall(r"\d+", s)
  print(res_list)
  # ['123', '45', '67']
  ```

### search

- 只匹配从左到右的第一个,得到的不是直接的结果,而是一个变量,通过这个变量的group方法来获取结果

  如果匹配不到结果, 返回值是一个 None, 不可以通过 group 方法进行取值

  ```python
  import re
  
  s = "123abc45de67"
  
  res = re.search(r"\d+", s)
  
  # 只会返回第一个结果
  print(res.group())
  # 123
  ```

### match

- 从头开始匹配,相当于search中的正则表达式加上一个 ^

  ```python
  import re
  
  s = "123abc45de67"
  
  res = re.match(r"\d+", s)
  print(res.group())
  # 123
  
  s1 = "aa123abc45de67"
  res = re.match(r"\d+", s1)
  print(res)
  # None
  ```

## 字符串的处理(切割,替换)

### 切割

```python
import re

s = "123abc45de67"

res = re.split(r"\d+", s)
print(res)
# ['', 'abc', 'de', '']
```

### 替换

- sub

  ```python
  import re
  
  s = "123abc45de67"
  
  res = re.sub(r"\d+", "0", s)
  print(res)
  # 0abc0de0
  
  res = re.sub(r"\d+", "xx", s)
  print(res)
  # xxabcxxdexx
  ```

- subn

  ```python
  import re
  
  s = "123abc45de67"
  
  res = re.subn(r"\d+", "0", s)
  print(res)
  # ('0abc0de0', 3)
  
  res = re.subn(r"\d+", "0", s, 1)
  print(res)
  # ('0abc45de67', 1)
  
  res = re.subn(r"\d+", "xx", s, 1)
  print(res)
  # ('xxabc45de67', 1)
  ```

## re模块的进阶

### compile

- 节省你使用正则表达式解决问题的时间

  - 优化前

    ```python
    import re
    import time
    
    s = "123abc45de67"
    
    start_time = time.time()
    for item in range(100000):
        re.findall(r"\d+", s)
    end_time = time.time()
    
    print(f"执行时间 {end_time - start_time}")
    # 执行时间 0.16196393966674805
    ```

  - 优化后的结果

    ```python
    import re
    import time
    
    s = "123abc45de67"
    
    # 提前将正则表达式进行编译
    c = re.compile(r"\d+")
    
    start_time = time.time()
    for item in range(100000):
        c.findall(s)
    end_time = time.time()
    
    print(f"执行时间 {end_time - start_time}")
    # 执行时间 0.10502195358276367
    ```

### finditer

- 节省你使用正则表达式解决问题的空间/内存

  返回的结果是一个可迭代对象

  ```python
  from collections.abc import Iterable
  import re
  
  s = "123abc45de67"
  
  res_iter = re.finditer(r"\d+", s)
  
  print(res_iter)
  # <callable_iterator object at 0x1063cfda0>
  
  # 是一个可迭代对象
  print(isinstance(res_iter, Iterable))
  # True
  
  # print(list(res_iter))
  # [<re.Match object; span=(0, 3), match='123'>, <re.Match object; span=(6, 8), match='45'>, <re.Match object; span=(10, 12), match='67'>]
  
  # 通过 group() 方法取值
  res = [item.group() for item in res_iter]
  print(res)
  # ['123', '45', '67']
  ```

### 两者综合使用

```python
import re

s = "123abc45de67"

c = re.compile(r"\d+")

res_iter = c.finditer(s)

res = [item.group() for item in res_iter]
print(res)
# ['123', '45', '67']
```

## 分组

### search中的分组

```python
import re

s = "<span>test1</span>"

c = re.compile(r"<(\w+)>(\w+)<(/\w+)>")

res = c.search(s)
print(res)
# <re.Match object; span=(0, 18), match='<span>test1</span>'>

# 如果取第0项代表取所有数据, 默认是第0项
print(res.group())
# <span>test1</span>
print(res.group(0))
# <span>test1</span>

print(res.group(1))
# span

print(res.group(2))
# test1
```

### findall中的分组

```python
import re

s = "<span>test1</span>"

c = re.compile(r"<(\w+)>(\w+)<(/\w+)>")
res = c.findall(s)

print(res)
# [('span', 'test1', '/span')]
```

- findall 会优先获取分组中的数据

  ```python
  import re
  
  s = "<span>test1</span>"
  
  c = re.compile(r"<\w+>(\w+)</\w+>")
  
  res = c.findall(s)
  
  print(res)
  # ['test1']
  ```

### 取消优先分组

- 在分组的前面加上 ?:

  ```python
  import re
  
  s = "<span>test1</span>33"
  
  c = re.compile(r"<\w+>(?:\w+)</\w+>")
  
  res = c.findall(s)
  
  print(res)
  # ['<span>test1</span>']
  ```

### 命名分组

- 取值

  ```python
  import re
  
  s = "<span>test1</span>33"
  
  c = re.compile(r"<(?P<tab1>\w+)>(?P<data>\w+)</(?P<tab2>\w+)>")
  
  res_iter = c.finditer(s)
  
  for item in res_iter:
      print(item.group("tab1"))
      print(item.group("data"))
      print(item.group("tab2"))
  ```

- 取分组

  ```python
  import re
  
  s = "<span>test1</span>33"
  
  c = re.compile(r"<(?P<tag>\w+)>(?P<data>\w+)</(?P=tag)>")
  
  res_iter = c.finditer(s)
  
  for item in res_iter:
      print(item.group("tag"))
      print(item.group("data"))
  
  # 如果前后的标签名不一样, 取不到对应数据
  s1 = "<span>test1</spadsn>33"
  res_iter = c.finditer(s1)
  print(len(list(res_iter)))
  # 0
  ```

## 爬虫示例

- 爬取豆瓣电影前10页数据

  ```python
  from urllib import request
  import re
  
  pattern = r'<div class="info">.+?<span class="title">(?P<title>.+?)</span>.+?<span class="rating_num".+?>(?P<score>.+?)</span>.+?<span>(?P<person>\d+?人评价)</span>.+?<span class="inq">(?P<content>.+?)</span>'
  c = re.compile(pattern, re.S)
  
  
  def request_net_data(url):
      res = str(request.urlopen(url).read(), "utf-8")
  
      res_iter = c.finditer(res)
      for item in res_iter:
          yield {
              "title": item.group("title"),
              "score": item.group("score"),
              "person": item.group("person"),
              "content": item.group("content")
          }
  
  
  def get_current_page_data(page_index):
      """
      爬取指定页数据
      :param page_index:
      :return:
      """
      data_index = 25 * (page_index - 1)
      url = f"https://movie.douban.com/top250?start={data_index}"
      return request_net_data(url)
  
  
  if __name__ == '__main__':
      data_list = list()
      for item in range(1, 6):
          for item_movie in get_current_page_data(item):
              data_list.append(item_movie)
  
      print(data_list)
  ```

