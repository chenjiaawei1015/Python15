# 线程

## 锁

- 对于线程来说, 虽然 Python 提供了全局解释器锁 GIL , 但是实际上在多线程操作相同的数据时, 仍需要进行加载处理

### 多线程抢占资源

- 不使用锁的情况, 多线程操作数据有可能出现数据的不安全问题

  ```python
  from threading import Thread
  import time
  import random
  
  
  def func():
      global data
      temp = data
      # 模拟延时
      time.sleep(random.random())
      temp = temp - 1
      data = temp
  
  
  if __name__ == '__main__':
      thread_num = 5
  
      data = thread_num
  
      thread_list = []
      for item in range(thread_num):
          th = Thread(target=func)
          thread_list.append(th)
  
      [item.start() for item in thread_list]
      [item.join() for item in thread_list]
  
      print(data)
  
  # 4
  ```

### 互斥锁

```python
from threading import Thread
import time
import random
from threading import Lock


def func():
    global data
    # 申请锁
    lock.acquire()

    temp = data
    # 模拟延时
    time.sleep(random.random())
    temp = temp - 1
    data = temp

    # 释放锁
    lock.release()


if __name__ == '__main__':
    thread_num = 5

    # 多线程同时操作 data 数据
    data = thread_num

    # 创建互斥锁
    lock = Lock()

    thread_list = []
    for item in range(thread_num):
        th = Thread(target=func)
        thread_list.append(th)

    [item.start() for item in thread_list]
    [item.join() for item in thread_list]

    print(data)
    
# 0    
```

### 死锁

- 是指两个或两个以上的进程或线程在执行过程中, 因争夺资源而造成的一种互相等待的现象, 若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程

- 线程中的死锁

  ```python
  from threading import Thread
  import threading
  import time
  import random
  from threading import Lock
  
  
  def func1():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
  
  def func2():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      lock_a = Lock()
      lock_b = Lock()
  
      th1 = Thread(target=func1, name=f'线程1')
      th2 = Thread(target=func2, name=f'线程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'子线程执行完毕')
  
  # 线程1 获取到 A 锁
  # 线程2 获取到 B 锁
  
  
  # 问题现象:
  # 线程1需要抢占 B 锁, 但是被线程2抢占了
  # 线程2需要抢占 A 锁, 但是被线程1抢占了
  # 程序卡住
  ```

- 进程中的死锁

  ```python
  from multiprocessing import Process
  from multiprocessing import Lock
  import multiprocessing
  import time
  import random
  
  
  def func1():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
  
  def func2():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      lock_a = Lock()
      lock_b = Lock()
  
      th1 = Process(target=func1, name=f'进程1')
      th2 = Process(target=func2, name=f'进程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'进程执行完毕')
  
  # 进程1 获取到 A 锁
  # 进程2 获取到 B 锁
  ```

### 递归锁

- Python中为了支持在同一线程中多次请求同一资源，python提供了可重入锁RLock

- 处理线程的死锁问题

  ```python
  from threading import Thread
  import threading
  import time
  import random
  from threading import Lock
  from threading import RLock
  
  
  def func1():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
  
  def func2():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      # 将互斥锁 Lock 替换为 递归锁 RLock
      lock_a = lock_b = RLock()
  
      th1 = Thread(target=func1, name=f'线程1')
      th2 = Thread(target=func2, name=f'线程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'子线程执行完毕')
  
  # 线程1 获取到 A 锁
  # 线程1 获取到 B 锁
  # 线程1 释放 B 锁
  # 线程1 释放 A 锁
  # 线程2 获取到 B 锁
  # 线程2 获取到 A 锁
  # 线程2 释放 A 锁
  # 线程2 释放 B 锁
  # 子线程执行完毕
  ```

- 处理进程的死锁问题

  ```python
  from multiprocessing import Process
  from multiprocessing import RLock
  import multiprocessing
  import time
  import random
  
  
  def func1():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
  
  def func2():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      # 同样替换为递归锁 RLock
      lock_a = lock_b = RLock()
  
      th1 = Process(target=func1, name=f'进程1')
      th2 = Process(target=func2, name=f'进程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'进程执行完毕')
  
  # 进程1 获取到 A 锁
  # 进程1 获取到 B 锁
  # 进程1 释放 B 锁
  # 进程1 释放 A 锁
  # 进程2 获取到 B 锁
  # 进程2 获取到 A 锁
  # 进程2 释放 A 锁
  # 进程2 释放 B 锁
  # 进程执行完毕
  ```

## 信号量

- 同进程的一样, Semaphore管理一个内置的计数器, 每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1；计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()
- **信号量可以使程序指定个数的线程同时持有锁**

```python
from threading import Thread
from threading import Semaphore
import threading
import time


def get_current_time():
    return time.strftime('%X')


def func():
    th = threading.current_thread()
    thread_name = th.name

    sem.acquire()
    print(f'{thread_name} 在 {get_current_time()} 执行')
    time.sleep(2)
    sem.release()


if __name__ == '__main__':
    sem = Semaphore(3)

    thread_list = []
    for item in range(10):
        th = Thread(target=func, name=f'线程{item}')
        thread_list.append(th)

    [item.start() for item in thread_list]
    [item.join() for item in thread_list]

    print(f'主线程执行完毕')

# 线程0 在 15:08:10 执行
# 线程1 在 15:08:10 执行
# 线程2 在 15:08:10 执行
# 线程3 在 15:08:12 执行
# 线程4 在 15:08:12 执行
# 线程5 在 15:08:12 执行
# 线程7 在 15:08:14 执行
# 线程6 在 15:08:14 执行
# 线程8 在 15:08:14 执行
# 线程9 在 15:08:16 执行
# 主线程执行完毕
```

## 事件

- 同进程的一样, 线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作,这时线程同步问题就会变得非常棘手。
- 为了解决这些问题,我们需要使用threading库中的Event对象。 对象包含一个可由线程设置的信号标志,它允许线程等待某些事件的发生。在 初始情况下,Event对象中的信号标志被设置为假。如果有线程等待一个Event对象, 而这个Event对象的标志为假,那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个Event对象的信号标志设置为真,它将唤醒所有等待这个Event对象的线程。如果一个线程等待一个已经被设置为真的Event对象,那么它将忽略这个事件, 继续执行

### 方法介绍

- event.isSet()：返回event的状态值
- event.wait()：如果 event.isSet()==False将阻塞线程；
- event.set()： 设置event的状态值为True，所有阻塞池的线程激活进入就绪状态， 等待操作系统调度；
- event.clear()：恢复event的状态值为False

### 示例

```python
# 模拟mysql的连接, 如果连接失败等待1s后进行重试, 失败3次提示连接失败

from threading import Thread
from threading import Event
import time
import random


def get_current_time():
    return time.strftime('%X')


def connect_mysql():
    connect_count = 1
    while 1:
        if event.is_set():
            print(f'连接成功')
            break
        elif connect_count > 3:
            print(f'连接失败')
            break
        else:
            print(f'{get_current_time()} 第 {connect_count} 次尝试连接, 连接失败')
            connect_count += 1
            # 不加参数的情况下是阻塞, 直到收到 event.set() 为止
            # 如果设置了一个参数, 这个参数代表等待的秒数
            # 这里等待1s, 1s后再回到循环中进行判断
            event.wait(1)


def change_state():
    time.sleep(random.randint(2, 5))
    event.set()


if __name__ == '__main__':
    event = Event()

    state_th = Thread(target=change_state)
    state_th.start()

    conn_th = Thread(target=connect_mysql)
    conn_th.start()

    state_th.join()
    conn_th.join()

# 情形1:
# 15:33:54 第 1 次尝试连接, 连接失败
# 15:33:55 第 2 次尝试连接, 连接失败
# 15:33:56 第 3 次尝试连接, 连接失败
# 连接失败

# 情形2:
# 15:34:28 第 1 次尝试连接, 连接失败
# 15:34:29 第 2 次尝试连接, 连接失败
# 连接成功
```

## 条件

- 使得线程等待，只有满足某条件时，才释放n个线程
- Python提供的Condition对象提供了对复杂线程同步问题的支持。Condition被称为条件变量，除了提供与Lock类似的acquire和release方法外，还提供了wait和notify方法。线程首先acquire一个条件变量，然后判断一些条件。如果条件不满足则wait；如果条件满足，进行一些处理改变条件后，通过notify方法通知其他线程，其他处于wait状态的线程接到通知后会重新判断条件。不断的重复这一过程，从而解决复杂的同步问题

```python
import threading
import time


def get_current_time():
    return time.strftime('%X')


def run():
    name = threading.current_thread().name

    # acquire 不会加锁
    con.acquire()
    
    # wait() 方法会进行加锁
    con.wait()
    print(f'{name} 在 {get_current_time()} 执行')
    con.release()


if __name__ == '__main__':

    # 创建条件
    con = threading.Condition()
    for i in range(10):
        t = threading.Thread(target=run, name=f'线程{i}')
        t.start()

    while True:
        inp = input('请输入开启的线程个数 : ')
        if inp == 'q':
            break

        con.acquire()

        # 允许指定线程个数开启
        con.notify(int(inp))

        con.release()

    print('主线程结束')

# 请输入开启的线程个数 : 4
# 线程1 在 17:28:20 执行
# 线程2 在 17:28:20 执行
# 线程3 在 17:28:20 执行
# 线程0 在 17:28:20 执行
# 请输入开启的线程个数 : 2
# 线程5 在 17:28:23 执行
# 线程4 在 17:28:23 执行
# 请输入开启的线程个数 : q
```

## 定时器

- 定时器，指定n秒后执行某个操作

  ```python
  from threading import Timer
  import time
  
  
  def func():
      print(f"{time.strftime('%X')}")
  
  
  if __name__ == '__main__':
      # 只执行一次
      timer = Timer(interval=1, function=func)
      timer.start()
  
  # 17:32:58
  ```

## 线程队列

- queue队列 ：使用import queue，用法与进程Queue一样

  ```python
  import queue
  
  if __name__ == '__main__':
      q = queue.Queue()
      q.put(1)
      q.put('2')
      q.put([1, 2, 3])
  
      print(q.empty())
      print(q.full())
  
      print(q.qsize())
  
      print(q.get())
      # 1
  
      print(q.get())
      # 2
  
      print(q.get())
      # [1, 2, 3]
  ```

- 队列的几种形式

  - 先进先出

    默认创建的队列为先进先出形式

  - 先进后出

    类似Java的堆栈

    ```python
    import queue
    
    if __name__ == '__main__':
        q = queue.LifoQueue()
        q.put(1)
        q.put('2')
        q.put([1, 2, 3])
    
        print(q.get())
        print(q.get())
        print(q.get())
    
    # [1, 2, 3]
    # 2
    # 1
    ```

  - 优先级

    数字越小, 优先级越高

    ```python
    import queue
    
    if __name__ == '__main__':
        q = queue.PriorityQueue()
        # put进入一个元组, 元组的第一个元素是优先级(通常是数字,也可以是非数字之间的比较), 数字越小优先级越高
        q.put((10, 'a'))
        q.put((30, 'b'))
        q.put((20, 'c'))
    
        print(q.get())
        print(q.get())
        print(q.get())
    
    # (10, 'a')
    # (20, 'c')
    # (30, 'b')
    ```

## threadingLocal

- 内部会为当前的线程单独创建一个空间用于数据存储, 保障不同线程取数据时不会相互冲突

- 示例

  ```python
  import threading
  import time
  
  # 创建一个 local 对象
  local = threading.local()
  
  
  def task(arg):
      local.data = arg
      print(f"线程 {threading.current_thread().name} 存数据 : {arg}")
      time.sleep(1)
      print(f"线程 {threading.current_thread().name} 取数据 : {local.data}")
  
  
  if __name__ == '__main__':
      for item in range(5):
          th = threading.Thread(target=task, args=(item,))
          th.start()
  
  # 线程 Thread-1 存数据 : 0
  # 线程 Thread-2 存数据 : 1
  # 线程 Thread-3 存数据 : 2
  # 线程 Thread-4 存数据 : 3
  # 线程 Thread-5 存数据 : 4
  # 线程 Thread-1 取数据 : 0
  # 线程 Thread-3 取数据 : 2
  # 线程 Thread-5 取数据 : 4
  # 线程 Thread-2 取数据 : 1
  # 线程 Thread-4 取数据 : 3
  
  # 可以发现不同线程存取数据时不会相互影响
  ```

- 模拟 ThreadLocal 的实现

  ```python
  import threading
  import time
  
  
  class Local:
      data_dict = dict()
      """
      保存所有的线程数据
      
      格式:
      # 1101 和 1102 分别代表两个线程的线程id
      {
          1101: {k1: v1, k2: v2},
          1102: {k1: v1, k2: v2}
      }
      """
  
      @staticmethod
      def get_thread_id():
          """
          获取当前的线程id
          :return:
          """
          return threading.current_thread().ident
  
      def __setattr__(self, key, value):
          thread_id = Local.get_thread_id()
          if thread_id in Local.data_dict:
              obj = Local.data_dict.get(thread_id)
              obj[key] = value
          else:
              obj = {key: value}
              Local.data_dict[thread_id] = obj
  
      def __getattr__(self, item):
          thread_id = Local.get_thread_id()
          obj = Local.data_dict.get(thread_id)
          return obj[item]
  
  
  # 创建一个 local 对象
  local = Local()
  
  
  def task(arg):
    	# 会调用 __setattr__ 方法
      local.data = arg
      print(f"线程 {threading.current_thread().name} 存数据 : {arg}")
      time.sleep(1)
      # 取数据的 local.data 会调用 __getattr__ 方法
      print(f"线程 {threading.current_thread().name} 取数据 : {local.data}")
  
  
  if __name__ == '__main__':
      for index in range(5):
          th = threading.Thread(target=task, args=(index,))
          th.start()
  
  # 线程 Thread-1 存数据 : 0
  # 线程 Thread-2 存数据 : 1
  # 线程 Thread-3 存数据 : 2
  # 线程 Thread-4 存数据 : 3
  # 线程 Thread-5 存数据 : 4
  # 线程 Thread-1 取数据 : 0
  # 线程 Thread-3 取数据 : 2
  # 线程 Thread-5 取数据 : 4
  # 线程 Thread-2 取数据 : 1
  # 线程 Thread-4 取数据 : 3
  ```

## concurrent.futures模块

### 介绍

- concurrent.futures模块提供了高度封装的异步调用接口
- ThreadPoolExecutor：线程池，提供异步调用
- ProcessPoolExecutor: 进程池，提供异步调用

### 基本方法

- 初始化方法

  对于 ThreadPoolExecutor 与 ProcessPoolExecutor 在创建对象的时候, 可以提供一个参数, 表示线程池中最多允许创建的线程数目

  例如:

  ```python
  from concurrent.futures import ThreadPoolExecutor
  
  # 最多允许创建3个线程
  executor = ThreadPoolExecutor(3)
  ```

- submit(fn, *args, **kwargs)

  异步提交任务

- map(func, *iterables, timeout=None, chunksize=1) 

  取代for循环submit的操作

- shutdown(wait=True)

  相当于进程池的pool.close()+pool.join()操作

  - wait=True，等待池内所有任务执行完毕回收完资源后才继续
  - wait=False，立即返回，并不会等待池内的任务执行完毕

  但不管wait参数为何值，整个程序都会等到所有任务执行完毕

  submit和map必须在shutdown之前

- result(timeout=None)

  取得结果

- add_done_callback(fn)

  回调函数

### 进程池

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    print(f'子进程 {pro.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    # 创建进程池
    executor = ProcessPoolExecutor()

    feature_list = []
    for item in range(5):
        # 通过进程池执行任务
        future = executor.submit(func, item)
        feature_list.append(future)

    executor.shutdown()

    print(f'主进程执行完毕')

    for item in feature_list:
        # 获取每个进程的结果
        print(item.result())

# 子进程 SpawnProcess-2 在 19:45:37 执行 : 0
# 子进程 SpawnProcess-6 在 19:45:37 执行 : 1
# 子进程 SpawnProcess-4 在 19:45:37 执行 : 2
# 子进程 SpawnProcess-8 在 19:45:37 执行 : 3
# 子进程 SpawnProcess-3 在 19:45:37 执行 : 4
# 主进程执行完毕
# 0
# 1
# 4
# 9
# 16
```

### 线程池

- 与进程池的操作类似

```python
from concurrent.futures import ThreadPoolExecutor
import time
import datetime


def get_current_time():
    return datetime.datetime.strftime(datetime.datetime.now(), "%X")


def task(data):
    res = data ** 2
    time.sleep(2)
    return res


if __name__ == '__main__':
    executor = ThreadPoolExecutor(3)

    feature_list = list()
    for item in range(10):
        feature_list.append(executor.submit(task, item))

    for item in feature_list:
        res_data = item.result()
        print(f"{get_current_time()} 返回数据 : {res_data}")

# 17:47:17 返回数据 : 0
# 17:47:17 返回数据 : 1
# 17:47:17 返回数据 : 4
# 17:47:19 返回数据 : 9
# 17:47:19 返回数据 : 16
# 17:47:19 返回数据 : 25
# 17:47:21 返回数据 : 36
# 17:47:21 返回数据 : 49
# 17:47:21 返回数据 : 64
# 17:47:23 返回数据 : 81
```

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    feature_list = []
    for item in range(5):
        feature = executor.submit(func, item)
        feature_list.append(feature)

    executor.shutdown()

    for item in feature_list:
        print(item.result())

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 19:52:14 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 19:52:14 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 19:52:14 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 19:52:14 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 19:52:14 执行 : 3
# 0
# 1
# 4
# 9
# 16
```

### map操作

- 简化了 for + submit 操作
- 缺点: 不能获取返回值

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    data_iter = (item for item in range(5))
    executor.map(func, data_iter)

    executor.shutdown()

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 19:56:41 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 19:56:41 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 19:56:41 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 19:56:41 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 19:56:41 执行 : 3
```

### 回调函数

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


def func_callback(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    print(f'进程 {pro.name} 子线程 {th.name} 获取回调的值 : {data.result()}')


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    for item in range(5):
        # 设置回调函数
        executor.submit(func, item).add_done_callback(func_callback)

    executor.shutdown()

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 20:02:33 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 获取回调的值 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 20:02:33 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 20:02:33 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 获取回调的值 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 获取回调的值 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 20:02:33 执行 : 3
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 获取回调的值 : 9
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 20:02:33 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 获取回调的值 : 16
```

### 案例:爬取网页数据

```python
from concurrent.futures import ThreadPoolExecutor
import requests


def request_url(url):
    data = requests.get(url)
    return {
        'url': data.url,
        'status_code': data.status_code,
        'content_length': len(data.content)
    }


def request_callback(url_data):
    print(url_data.result())


if __name__ == '__main__':
    url_list = [
        'http://www.baidu.com',
        'http://www.qq.com',
        'http://www.163.com',
        'http://www.hao123.com',
    ]

    executor = ThreadPoolExecutor()

    for item in url_list:
        executor.submit(request_url, item).add_done_callback(request_callback)

    executor.shutdown()

# {'url': 'http://www.baidu.com/', 'status_code': 200, 'content_length': 2381}
# {'url': 'http://www.qq.com/', 'status_code': 200, 'content_length': 245170}
# {'url': 'http://www.163.com/', 'status_code': 200, 'content_length': 704972}
# {'url': 'http://www.hao123.com/', 'status_code': 200, 'content_length': 509395}
```

## 生产者消费者模型

在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度

- ##### **为什么要使用生产者和消费者模式**

  在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式

- ##### **什么是生产者消费者模式**

  生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力

### 基于队列实现生产者消费者模型

#### 第一版

```python
from multiprocessing import Process
from multiprocessing import Queue
import random
import time


def consumer(queue, index):
    while 1:
        data = queue.get()
        print(f'消费者{index} 消费 {data}')


def producer(queue):
    for index in range(10):
        time.sleep(random.randint(0, 2))
        queue.put(index)
        print(f'生产者 生产 {index}')


if __name__ == '__main__':
    queue = Queue()
    pro = Process(target=producer, args=(queue,))

    consumer_list = []
    for index in range(5):
        p = Process(target=consumer, args=(queue, index))
        consumer_list.append(p)

    for item in consumer_list:
        item.start()

    pro.start()
```

- 问题

  1. 主进程永远不会结束

     生产者p在生产完后就结束了，但是消费者c在取空了q之后，则一直处于死循环中且卡在q.get()这一步

- 解决方法

  让生产者在生产完毕后，往队列中再发一个结束信号，这样消费者在接收到结束信号后就可以break出死循环

#### 第二版

```python
from multiprocessing import Process
from multiprocessing import Queue
import random
import time


def consumer(queue, index):
    while 1:
        data = queue.get()

        if not data:
            print(f'消费者进程{index} 结束')
            break

        print(f'消费者{index} 消费 {data}')


def producer(queue, consumer_size):
    for index in range(1, 10):
        time.sleep(random.randint(0, 2))
        queue.put(index)
        print(f'生产者 生产 {index}')

    for index in range(consumer_size):
        queue.put(None)


if __name__ == '__main__':
    # 消费者的个数
    consumer_size = 5
    # 创建队列
    queue = Queue()

    pro = Process(target=producer, args=(queue, consumer_size))

    consumer_list = []
    for index in range(consumer_size):
        p = Process(target=consumer, args=(queue, index))
        consumer_list.append(p)

    for item in consumer_list:
        item.start()

    pro.start()
```

**上述虽然解决了主进程无法关闭的问题, 但是缺点在于消费者生产数据完毕后, 对于 None 的传入, 有多少个消费者就必须传入指定个 None值**

#### 第三版

- JoinableQueue

  创建可连接的共享进程队列。这就像是一个Queue对象，但队列允许项目的使用者通知生产者项目已经被成功处理。通知进程是使用共享的信号和条件变量来实现的

  ```
  JoinableQueue的实例p除了与Queue对象相同的方法之外，还具有以下方法：
  
  q.task_done() 
  使用者使用此方法发出信号，表示q.get()返回的项目已经被处理。如果调用此方法的次数大于从队列中删除的项目数量，将引发ValueError异常。
  
  q.join() 
  生产者将使用此方法进行阻塞，直到队列中所有项目均被处理。阻塞将持续到为队列中的每个项目均调用q.task_done()方法为止。 
  下面的例子说明如何建立永远运行的进程，使用和处理队列上的项目。生产者将项目放入队列，并等待它们被处理。
  ```

- 多生产者多消费者模型

  ```python
  from multiprocessing import Process
  from multiprocessing import JoinableQueue
  import random
  import time
  
  
  def consumer(queue, consumer_name):
      while 1:
          data = queue.get()
          print(f'消费者{consumer_name} 消费 {data}')
          # 向q.join()发送一次信号,证明一个数据已经被取走了
          queue.task_done()
  
  
  def producer(queue, producer_name):
      for index in range(1, 5):
          time.sleep(random.randint(0, 2))
          queue.put(index)
          print(f'生产者{producer_name} 生产 {index}')
  
      # 生产完毕，使用此方法进行阻塞，直到队列中所有项目均被处理
      queue.join()
  
  
  if __name__ == '__main__':
      # 生产者个数
      producer_size = 3
      # 消费者的个数
      consumer_size = 5
      # 创建队列
      queue = JoinableQueue()
  
      producer_list = []
      for index in range(producer_size):
          pro = Process(target=producer, args=(queue, index))
          producer_list.append(pro)
  
      consumer_list = []
      for index in range(consumer_size):
          # 将消费者进程设置为守护进程
          p = Process(target=consumer, args=(queue, index))
          p.daemon = True
          consumer_list.append(p)
  
      for item in consumer_list:
          item.start()
  
      for item in producer_list:
          item.start()
  
      for item in producer_list:
          # 主进程等待生产者进程执行完毕
          item.join()
  ```

### 线程版本的生产者消费者模型

```python
import threading
import queue
import time
import random
from threading import RLock

# 数据索引
data_index = 0

# 锁, 保证 data_index 修改不受影响
lock = RLock()


def get_current_index():
    """
    获取当前索引
    :return:
    """
    global data_index
    lock.acquire()
    data_index += 1
    lock.release()
    return data_index


def get_thread_name():
    """
    获取线程名称
    :return:
    """
    return threading.current_thread().name


def consumer():
    """
    消费者
    :return:
    """
    while 1:
        data = data_queue.get()
        print(f"{get_thread_name()} 消费 {data}")
        data_queue.task_done()


def producer():
    """
    生产者
    :return:
    """
    for index in range(3):
        time.sleep(random.randint(1, 10) / 100)
        current_index = get_current_index()
        data_queue.put(current_index)
        print(f"{get_thread_name()} 生产 {current_index}")

    data_queue.join()


# 线程队列
data_queue = queue.Queue()

# 消费者线程列表
consumer_list = list()
for item in range(1, 10):
    th = threading.Thread(target=consumer)
    th.setName(f"消费者{item}")
    th.setDaemon(True)
    consumer_list.append(th)

# 生产者消费列表
producer_list = list()
for item in range(1, 4):
    th = threading.Thread(target=producer)
    th.setName(f"生产者{item}")
    producer_list.append(th)

# 开启 生产者 和 消费者 线程
[item.start() for item in producer_list]
[item.start() for item in consumer_list]
```

